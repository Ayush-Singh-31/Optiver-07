{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA3888 Project: Optiver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "from glob import glob\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing  import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = sorted(glob(\"Data/individual_book_train/*.csv\"))\n",
    "\n",
    "ldf = pl.scan_csv(\n",
    "    csv_files,\n",
    "    schema_overrides={         \n",
    "        'time_id': pl.Int64,\n",
    "        'seconds_in_bucket': pl.Int64,\n",
    "        'bid_price1': pl.Float64,\n",
    "        'ask_price1': pl.Float64,\n",
    "        'bid_price2': pl.Float64,\n",
    "        'ask_price2': pl.Float64,\n",
    "        'bid_size1': pl.Int64,\n",
    "        'ask_size1': pl.Int64,\n",
    "        'bid_size2': pl.Int64,\n",
    "        'ask_size2': pl.Int64,\n",
    "        'stock_id': pl.Int64,\n",
    "    },\n",
    "    infer_schema_length=0\n",
    ")\n",
    "\n",
    "# df = ldf.collect()  \n",
    "# df.write_parquet(\"Data/Combined_book_train.parquet\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\n",
    "    \"Data/Combined_book_train.parquet\",\n",
    "    use_pyarrow=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 300   \n",
    "df['window_start'] = (df['seconds_in_bucket'] // window_size) * window_size\n",
    "\n",
    "agg = (\n",
    "    df\n",
    "    .groupby(['stock_id', 'time_id', 'window_start'], as_index=False)\n",
    "    .agg({\n",
    "        'bid_price1':  'mean',\n",
    "        'ask_price1':  'mean',\n",
    "        'bid_price2':  'mean',\n",
    "        'ask_price2':  'mean',\n",
    "        'bid_size1':   'sum',\n",
    "        'ask_size1':   'sum',\n",
    "        'bid_size2':   'sum',\n",
    "        'ask_size2':   'sum',\n",
    "    })\n",
    ")\n",
    "\n",
    "agg['seconds_in_bucket'] = agg['window_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  26,  27,  28,\n",
       "        29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "        42,  43,  44,  46,  47,  48,  50,  51,  52,  53,  55,  56,  58,\n",
       "        59,  60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  72,  73,\n",
       "        74,  75,  76,  77,  78,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "        88,  89,  90,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "       103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       118, 119, 120, 122, 123, 124, 125, 126])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg[\"stock_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 31, 77, 43, 29, 41, 108, 111, 47, 124, 46, 35, 119, 44, 125, 69, 21, 13, 86, 99, 63, 123, 14, 10, 120, 85, 105, 89, 74, 50]\n"
     ]
    }
   ],
   "source": [
    "summary = (agg\n",
    "    .groupby('stock_id')\n",
    "    .agg(\n",
    "        avg_bid_size1   = ('bid_size1', 'mean'),\n",
    "        avg_ask_size1   = ('ask_size1', 'mean'),\n",
    "        avg_bid_size2   = ('bid_size2', 'mean'),\n",
    "        avg_ask_size2   = ('ask_size2', 'mean'),\n",
    "        avg_bid_price1  = ('bid_price1','mean'),\n",
    "        avg_ask_price1  = ('ask_price1','mean'),\n",
    "    )\n",
    ")\n",
    "\n",
    "summary['spread']    = summary['avg_ask_price1'] - summary['avg_bid_price1']\n",
    "summary['depth']     = summary[['avg_bid_size1','avg_ask_size1','avg_bid_size2','avg_ask_size2']].mean(axis=1)\n",
    "summary['liq_score'] = summary['depth'] / summary['spread']\n",
    "\n",
    "k = 30\n",
    "top_liquid = summary.nlargest(k, 'liq_score').index.tolist()\n",
    "print(top_liquid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 8, 9, 11, 16, 18, 27, 31, 33, 44, 56, 62, 63, 74, 75, 80, 81, 83, 88, 89, 90, 94, 97, 100, 112, 124]\n"
     ]
    }
   ],
   "source": [
    "df = agg.copy()\n",
    "\n",
    "df['mid'] = (df['bid_price1'] + df['ask_price1']) / 2\n",
    "df = df.sort_values(['stock_id','time_id','seconds_in_bucket'])\n",
    "df['mid_prev'] = df.groupby('stock_id')['mid'].shift(1)\n",
    "df['ret']     = np.log(df['mid'] / df['mid_prev'])\n",
    "\n",
    "vol = df.groupby('stock_id')['ret'].var().rename('ret_var')\n",
    "\n",
    "threshold = vol.quantile(0.75)\n",
    "high_vol = vol[vol > threshold].index.tolist()\n",
    "print(high_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 32, 77, 108, 41, 43, 29, 111, 47, 35, 37, 33, 98, 5, 103, 112, 18, 75, 4, 27, 30, 0, 88, 16, 62, 116, 113, 110, 126, 90]\n"
     ]
    }
   ],
   "source": [
    "summary = summary.join(vol)\n",
    "\n",
    "X = StandardScaler().fit_transform(summary)\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "scores = pca.transform(X)   \n",
    "\n",
    "pc1_scores = pd.Series(np.abs(scores[:,0]), index=summary.index)\n",
    "top_pca = pc1_scores.nlargest(30).index.tolist()\n",
    "print(top_pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
