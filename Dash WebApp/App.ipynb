{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2212bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import dcc, html, Input, Output, State, ctx\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5041de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOTLY_TEMPLATE = \"plotly_white\"\n",
    "DBC_THEME = dbc.themes.LUX\n",
    "DATA_DIR = \"Data\"\n",
    "GENERAL_CSV_PATH = os.path.join(DATA_DIR, \"general.csv\")\n",
    "MODEL_FOLDERS = [\"WLS\", \"Random Forest\", \"LSTM\", \"Transformer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1e46e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_data_structure(base_dir=\"Data\"):\n",
    "    if os.path.exists(base_dir):\n",
    "        print(f\"'{base_dir}' directory already exists. Attempting to verify structure.\")\n",
    "        general_csv_exists = os.path.exists(os.path.join(base_dir, \"general.csv\"))\n",
    "        all_model_folders_exist = all(os.path.exists(os.path.join(base_dir, mf)) for mf in MODEL_FOLDERS)\n",
    "        \n",
    "        if general_csv_exists and all_model_folders_exist:\n",
    "            all_model_folders_have_data = True\n",
    "            for mf in MODEL_FOLDERS:\n",
    "                if not glob.glob(os.path.join(base_dir, mf, \"stock_*.csv\")): # Check for specific naming\n",
    "                    all_model_folders_have_data = False\n",
    "                    print(f\"Missing 'stock_*.csv' files in {os.path.join(base_dir, mf)}\")\n",
    "                    break\n",
    "            if all_model_folders_have_data:\n",
    "                print(\"Required dummy data structure seems to be in place.\")\n",
    "                return\n",
    "        else:\n",
    "            if not general_csv_exists: print(\"general.csv missing.\")\n",
    "            if not all_model_folders_exist: print(\"Some model folders missing.\")\n",
    "            print(\"Will attempt to create/recreate dummy data structure.\")\n",
    "    else:\n",
    "        os.makedirs(base_dir, exist_ok=True)\n",
    "        print(f\"Created base directory: {base_dir}\")\n",
    "\n",
    "    print(\"Generating dummy data structure...\")\n",
    "\n",
    "    # Define stock IDs to be used for filenames and in general.csv\n",
    "    num_stock_files_per_model = 2 \n",
    "    stock_id_names_for_files = [f\"{i}\" for i in range(num_stock_files_per_model)]\n",
    "\n",
    "    # General CSV\n",
    "    general_data = []\n",
    "    model_names_general = MODEL_FOLDERS\n",
    "\n",
    "    for stock_id_gen in stock_id_names_for_files: # Use consistent stock IDs\n",
    "        for model_name_gen in model_names_general:\n",
    "            general_data.append({\n",
    "                'stock_id': stock_id_gen,\n",
    "                'model_name': model_name_gen,\n",
    "                'mse': np.random.uniform(0.0005, 0.005),\n",
    "                'qlike': np.random.uniform(0.005, 0.05),\n",
    "                'r^2': np.random.uniform(0.6, 0.95)\n",
    "            })\n",
    "    df_general = pd.DataFrame(general_data)\n",
    "    df_general.to_csv(os.path.join(base_dir, \"general.csv\"), index=False)\n",
    "    print(f\"Generated '{os.path.join(base_dir, 'general.csv')}'\")\n",
    "\n",
    "    # Detailed model CSVs\n",
    "    num_time_ids_per_stock_file = 5 # e.g., time_id 0, 1, 2, 3, 4 within each stock file\n",
    "    points_per_time_id_segment = 10 # Number of true/pred_vol pairs for each time_id\n",
    "\n",
    "    for model_folder_name in MODEL_FOLDERS:\n",
    "        model_path = os.path.join(base_dir, model_folder_name)\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        \n",
    "        for stock_file_name_base in stock_id_names_for_files: # e.g., \"stock_0\"\n",
    "            detailed_data_for_stock_file = []\n",
    "            \n",
    "            for actual_time_id in range(num_time_ids_per_stock_file): # These are the time_ids within the file\n",
    "                segment_mse = np.random.uniform(0.0001, 0.008)\n",
    "                segment_qlike = np.random.uniform(0.001, 0.08)\n",
    "                segment_r2 = np.random.uniform(0.5, 0.98)\n",
    "\n",
    "                for _ in range(points_per_time_id_segment):\n",
    "                    true_vol = np.random.uniform(0.005, 0.15)\n",
    "                    pred_error = np.random.normal(0, 0.015)\n",
    "                    pred_vol = max(0.0001, true_vol + pred_error)\n",
    "                    detailed_data_for_stock_file.append({\n",
    "                        'stock_id': stock_file_name_base, # Stock ID is constant for this file, matches filename base\n",
    "                        'time_id': actual_time_id,       # This is the varying time_id\n",
    "                        'model_name': model_folder_name,\n",
    "                        'mse': segment_mse, # Per stock_id, time_id segment\n",
    "                        'qlike': segment_qlike,\n",
    "                        'r^2': segment_r2,\n",
    "                        'pred_vol': pred_vol,\n",
    "                        'true_vol': true_vol\n",
    "                    })\n",
    "            df_detailed_stock_file = pd.DataFrame(detailed_data_for_stock_file)\n",
    "            df_detailed_stock_file.to_csv(os.path.join(model_path, f\"{stock_file_name_base}.csv\"), index=False)\n",
    "        print(f\"Generated dummy data for model: {model_folder_name}\")\n",
    "    print(\"Dummy data structure generation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f6b45f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Data' directory already exists. Attempting to verify structure.\n",
      "Missing 'stock_*.csv' files in Data/WLS\n",
      "Generating dummy data structure...\n",
      "Generated 'Data/general.csv'\n",
      "Generated dummy data for model: WLS\n",
      "Generated dummy data for model: Random Forest\n",
      "Generated dummy data for model: LSTM\n",
      "Generated dummy data for model: Transformer\n",
      "Dummy data structure generation complete.\n"
     ]
    }
   ],
   "source": [
    "create_dummy_data_structure(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8528b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_general = pd.read_csv(GENERAL_CSV_PATH)\n",
    "    df_general['stock_id'] = df_general['stock_id'].astype(str)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: '{GENERAL_CSV_PATH}' not found. Please ensure it exists or re-run to generate dummy data.\")\n",
    "    df_general = pd.DataFrame(columns=['stock_id', 'model_name', 'mse', 'qlike', 'r^2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50d75121",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(__name__, external_stylesheets=[DBC_THEME], suppress_callback_exceptions=True)\n",
    "app.title = \"Advanced Volatility Model Analyzer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "337b58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = dbc.Container(fluid=True, className=\"py-3\", children=[\n",
    "    dbc.Row(dbc.Col(html.H1(\"Advanced Volatility Model Analyzer\", className=\"text-center text-primary mb-4\"))),\n",
    "\n",
    "    # Section 1: Overall Model Performance\n",
    "    dbc.Card(className=\"mb-4 shadow-sm\", body=True, children=[\n",
    "        html.H3(\"Overall Model Performance (from general.csv)\", className=\"card-title text-info mb-3\"),\n",
    "        dbc.Row([\n",
    "            dbc.Col(md=3, children=[\n",
    "                dbc.Label(\"Select Stock ID (Overall):\"),\n",
    "                dcc.Dropdown(\n",
    "                    id='overall-stock-id-dropdown',\n",
    "                    options=[{'label': i, 'value': i} for i in sorted(df_general['stock_id'].unique())],\n",
    "                    value=sorted(df_general['stock_id'].unique())[0] if df_general['stock_id'].nunique() > 0 else None,\n",
    "                    clearable=False,\n",
    "                )\n",
    "            ]),\n",
    "        ]),\n",
    "        dbc.Row([\n",
    "            dbc.Col(md=4, className=\"mt-3\", children=dcc.Loading(dcc.Graph(id='overall-mse-plot'))),\n",
    "            dbc.Col(md=4, className=\"mt-3\", children=dcc.Loading(dcc.Graph(id='overall-qlike-plot'))),\n",
    "            dbc.Col(md=4, className=\"mt-3\", children=dcc.Loading(dcc.Graph(id='overall-r2-plot'))),\n",
    "        ]),\n",
    "    ]),\n",
    "\n",
    "    # Section 2: Detailed Time ID Analysis\n",
    "    dbc.Card(className=\"mb-4 shadow-sm\", body=True, children=[\n",
    "        html.H3(\"Detailed Stock/Time ID Analysis\", className=\"card-title text-success mb-3\"),\n",
    "        dbc.Row([\n",
    "            dbc.Col(md=3, children=[\n",
    "                dbc.Label(\"Select Model Type:\"),\n",
    "                dcc.Dropdown(id='detail-model-type-dropdown', options=[{'label': m, 'value': m} for m in MODEL_FOLDERS], clearable=False, value=MODEL_FOLDERS[0]),\n",
    "            ]),\n",
    "            dbc.Col(md=3, children=[\n",
    "                dbc.Label(\"Select Stock ID File:\"), # CHANGED LABEL\n",
    "                dcc.Dropdown(id='detail-stock-id-file-dropdown', clearable=False), # CHANGED ID for clarity\n",
    "            ]),\n",
    "            dbc.Col(md=3, children=[\n",
    "                dbc.Label(\"Select Time ID (from file):\"), # CHANGED LABEL\n",
    "                dcc.Dropdown(id='detail-time-id-dropdown', clearable=False), # CHANGED ID for clarity\n",
    "            ]),\n",
    "            dbc.Col(md=3, className=\"align-self-end\", children=[\n",
    "                dbc.Button(\"Load & Analyze Segment\", id='load-analyze-button', color=\"primary\", className=\"w-100\") # CHANGED BUTTON TEXT\n",
    "            ]),\n",
    "        ]),\n",
    "        html.Div(id='detailed-analysis-plots-container', className=\"mt-3\", children=[\n",
    "            html.P(\"Select model, stock ID file, time ID, and click 'Load & Analyze' to see detailed plots.\", className=\"text-muted\")\n",
    "        ])\n",
    "    ]),\n",
    "    # dcc.Store(id='loaded-detailed-data-store'), # Not actively used in this version for simplicity\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e503899",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('overall-mse-plot', 'figure'),\n",
    "    Output('overall-qlike-plot', 'figure'),\n",
    "    Output('overall-r2-plot', 'figure'),\n",
    "    Input('overall-stock-id-dropdown', 'value')\n",
    ")\n",
    "def update_overall_plots(selected_overall_stock_id):\n",
    "    if not selected_overall_stock_id or df_general.empty:\n",
    "        empty_fig = go.Figure().update_layout(template=PLOTLY_TEMPLATE, title_text=\"No Data\")\n",
    "        return empty_fig, empty_fig, empty_fig\n",
    "\n",
    "    filtered_df = df_general[df_general['stock_id'] == selected_overall_stock_id]\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        empty_fig = go.Figure().update_layout(template=PLOTLY_TEMPLATE, title_text=f\"No Data for Stock {selected_overall_stock_id}\")\n",
    "        return empty_fig, empty_fig, empty_fig\n",
    "\n",
    "    fig_mse = px.bar(filtered_df, x='model_name', y='mse', color='model_name',\n",
    "                     title=f'MSE Comparison for Stock {selected_overall_stock_id}', template=PLOTLY_TEMPLATE,\n",
    "                     labels={'model_name': 'Model', 'mse': 'Mean Squared Error'})\n",
    "    fig_qlike = px.bar(filtered_df, x='model_name', y='qlike', color='model_name',\n",
    "                       title=f'QLIKE Comparison for Stock {selected_overall_stock_id}', template=PLOTLY_TEMPLATE,\n",
    "                       labels={'model_name': 'Model', 'qlike': 'QLIKE'})\n",
    "    fig_r2 = px.bar(filtered_df, x='model_name', y='r^2', color='model_name',\n",
    "                    title=f'R² Score Comparison for Stock {selected_overall_stock_id}', template=PLOTLY_TEMPLATE,\n",
    "                    labels={'model_name': 'Model', 'r^2': 'R² Score'})\n",
    "    \n",
    "    fig_mse.update_layout(showlegend=False)\n",
    "    fig_qlike.update_layout(showlegend=False)\n",
    "    fig_r2.update_layout(showlegend=False)\n",
    "    \n",
    "    return fig_mse, fig_qlike, fig_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c533993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('detail-stock-id-file-dropdown', 'options'), # CHANGED ID\n",
    "    Output('detail-stock-id-file-dropdown', 'value'),   # CHANGED ID\n",
    "    Input('detail-model-type-dropdown', 'value')\n",
    ")\n",
    "def set_stock_id_file_options(selected_model_type): # Renamed callback for clarity\n",
    "    if not selected_model_type:\n",
    "        return [], None\n",
    "    \n",
    "    model_data_path = os.path.join(DATA_DIR, selected_model_type)\n",
    "    if not os.path.exists(model_data_path):\n",
    "        return [], None\n",
    "        \n",
    "    # Expecting filenames like \"stock_0.csv\", \"stock_1.csv\"\n",
    "    csv_files = sorted([f for f in os.listdir(model_data_path) if f.endswith('.csv') and f[:-4].isdigit()])\n",
    "    options = [{'label': f, 'value': f} for f in csv_files]\n",
    "    value = csv_files[0] if csv_files else None\n",
    "    return options, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9140d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output('detail-time-id-dropdown', 'options'), # CHANGED ID\n",
    "    Output('detail-time-id-dropdown', 'value'),   # CHANGED ID\n",
    "    Input('detail-model-type-dropdown', 'value'),\n",
    "    Input('detail-stock-id-file-dropdown', 'value') # CHANGED ID\n",
    ")\n",
    "def set_detail_time_id_options(selected_model_type, selected_stock_id_filename): # Renamed callback and params\n",
    "    if not selected_model_type or not selected_stock_id_filename:\n",
    "        return [], None\n",
    "\n",
    "    file_path = os.path.join(DATA_DIR, selected_model_type, selected_stock_id_filename)\n",
    "    if not os.path.exists(file_path):\n",
    "        return [], None\n",
    "        \n",
    "    try:\n",
    "        temp_df = pd.read_csv(file_path)\n",
    "        # Ensure time_id is treated as string for dropdown if they are not purely numeric or to maintain order\n",
    "        temp_df['time_id'] = temp_df['time_id'].astype(str) \n",
    "        time_ids_from_file = sorted(temp_df['time_id'].unique())\n",
    "        options = [{'label': t_id, 'value': t_id} for t_id in time_ids_from_file]\n",
    "        value = time_ids_from_file[0] if time_ids_from_file else None\n",
    "        return options, value\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path} for time IDs: {e}\")\n",
    "        return [], None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "530da6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    # Output('loaded-detailed-data-store', 'data'), # Not using store for now\n",
    "    Output('detailed-analysis-plots-container', 'children'),\n",
    "    Input('load-analyze-button', 'n_clicks'),\n",
    "    State('detail-model-type-dropdown', 'value'),\n",
    "    State('detail-stock-id-file-dropdown', 'value'), # CHANGED ID\n",
    "    State('detail-time-id-dropdown', 'value'),       # CHANGED ID\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def load_and_display_detailed_data(n_clicks, model_type, selected_stock_id_filename, selected_time_id_from_file): # Renamed params\n",
    "    if not n_clicks or not model_type or not selected_stock_id_filename or not selected_time_id_from_file:\n",
    "        return html.P(\"Please make all selections and click 'Load & Analyze'.\", className=\"text-warning\")\n",
    "\n",
    "    file_path = os.path.join(DATA_DIR, model_type, selected_stock_id_filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return html.P(f\"Error: File not found - {file_path}\", className=\"text-danger\")\n",
    "\n",
    "    try:\n",
    "        df_full_detailed = pd.read_csv(file_path)\n",
    "        # Ensure consistent types for filtering\n",
    "        df_full_detailed['stock_id'] = df_full_detailed['stock_id'].astype(str)\n",
    "        df_full_detailed['time_id'] = df_full_detailed['time_id'].astype(str)\n",
    "        \n",
    "        # The stock_id for this file is derived from its name or its content (should be consistent)\n",
    "        # For filtering within the file, we use the selected_time_id_from_file\n",
    "        # The stock_id column in the file should match selected_stock_id_filename (without .csv)\n",
    "        # For robustness, we can filter on both if needed, but primarily time_id for this segment.\n",
    "        \n",
    "        # Filter for the selected time_id within the specific stock_id file\n",
    "        # The `stock_id` column in the CSV should ideally match `selected_stock_id_filename` (without .csv)\n",
    "        # For this filtering, we are interested in the specific time_id within that stock's file.\n",
    "        df_selected_segment = df_full_detailed[\n",
    "            (df_full_detailed['time_id'] == selected_time_id_from_file) &\n",
    "            (df_full_detailed['stock_id'] == selected_stock_id_filename.replace('.csv', ''))\n",
    "        ].copy()\n",
    "        \n",
    "        if df_selected_segment.empty:\n",
    "            return html.P(f\"No data found for Stock: {selected_stock_id_filename.replace('.csv', '')}, Time ID: {selected_time_id_from_file} in {selected_stock_id_filename}.\", className=\"text-warning\")\n",
    "\n",
    "        df_selected_segment['error'] = df_selected_segment['true_vol'] - df_selected_segment['pred_vol']\n",
    "        \n",
    "        stock_display_name = selected_stock_id_filename.replace('.csv', '')\n",
    "        segment_metrics = df_selected_segment[['mse', 'qlike', 'r^2']].iloc[0]\n",
    "        \n",
    "        metrics_display = html.Div([\n",
    "            html.H5(f\"Metrics for {model_type} - Stock: {stock_display_name} - Time ID: {selected_time_id_from_file}\", className=\"text-muted\"),\n",
    "            html.P(f\"MSE: {segment_metrics['mse']:.6f} | QLIKE: {segment_metrics['qlike']:.6f} | R²: {segment_metrics['r^2']:.6f}\", className=\"small\")\n",
    "        ], className=\"mb-3\")\n",
    "\n",
    "        fig_scatter_detail = px.scatter(\n",
    "            df_selected_segment, x='true_vol', y='pred_vol',\n",
    "            labels={'true_vol': 'True Volatility', 'pred_vol': 'Predicted Volatility'},\n",
    "            template=PLOTLY_TEMPLATE, marginal_y=\"histogram\", marginal_x=\"histogram\",\n",
    "            title=f\"Predicted vs. True Volatility (Stock: {stock_display_name}, Time: {selected_time_id_from_file})\"\n",
    "        )\n",
    "        min_val = min(df_selected_segment['true_vol'].min(), df_selected_segment['pred_vol'].min()) if not df_selected_segment.empty else 0\n",
    "        max_val = max(df_selected_segment['true_vol'].max(), df_selected_segment['pred_vol'].max()) if not df_selected_segment.empty else 1\n",
    "        fig_scatter_detail.add_shape(type='line', x0=min_val, y0=min_val, x1=max_val, y1=max_val, line=dict(color='Gray', dash='dash'))\n",
    "\n",
    "        df_line_plot = df_selected_segment.reset_index().rename(columns={'index': 'observation_index'})\n",
    "        fig_line_detail = go.Figure()\n",
    "        fig_line_detail.add_trace(go.Scatter(x=df_line_plot['observation_index'], y=df_line_plot['true_vol'], mode='lines+markers', name='True Vol', line=dict(dash='dot')))\n",
    "        fig_line_detail.add_trace(go.Scatter(x=df_line_plot['observation_index'], y=df_line_plot['pred_vol'], mode='lines+markers', name='Pred Vol'))\n",
    "        fig_line_detail.update_layout(template=PLOTLY_TEMPLATE, xaxis_title='Observation Index', yaxis_title='Volatility', title=f\"Volatility Over Time (Stock: {stock_display_name}, Time: {selected_time_id_from_file})\")\n",
    "\n",
    "        fig_hist_detail = px.histogram(\n",
    "            df_selected_segment, x='error', template=PLOTLY_TEMPLATE,\n",
    "            labels={'error': 'Prediction Error (True - Predicted)'},\n",
    "            title=f\"Prediction Error Distribution (Stock: {stock_display_name}, Time: {selected_time_id_from_file})\", marginal=\"box\"\n",
    "        )\n",
    "        fig_hist_detail.add_vline(x=0, line_width=2, line_dash=\"dash\", line_color=\"gray\")\n",
    "\n",
    "        detailed_plots_layout = dbc.Container(fluid=True, children=[\n",
    "            metrics_display,\n",
    "            dbc.Row([\n",
    "                dbc.Col(md=6, children=dcc.Graph(figure=fig_scatter_detail)),\n",
    "                dbc.Col(md=6, children=dcc.Graph(figure=fig_line_detail)),\n",
    "            ]),\n",
    "            dbc.Row([\n",
    "                dbc.Col(md=6, className=\"mt-3\", children=dcc.Graph(figure=fig_hist_detail)),\n",
    "                dbc.Col(md=6, className=\"mt-3\") \n",
    "            ])\n",
    "        ])\n",
    "        \n",
    "        return detailed_plots_layout\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing detailed data from {file_path}: {e}\")\n",
    "        return html.Div([\n",
    "            html.P(f\"An error occurred while loading or processing data from {file_path}.\", className=\"text-danger\"),\n",
    "            html.Pre(str(e))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
