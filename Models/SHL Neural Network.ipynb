{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72017617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd952db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/hanzichun/desktop/Optiver-07/Data/individual_book_train/stock_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d3daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mid_price'] = (df['bid_price1'] + df['ask_price1']) / 2\n",
    "df['spread'] = df['ask_price1'] - df['bid_price1']\n",
    "df['imbalance'] = (df['bid_size1'] - df['ask_size1']) / (df['bid_size1'] + df['ask_size1'] + 1e-8)\n",
    "df['wap'] = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'] + 1e-8)\n",
    "df['log_wap_return'] = np.log(df['wap'] / df['wap'].shift(1)).fillna(0)\n",
    "\n",
    "\n",
    "df['log_return'] = np.log(df['mid_price'] / df['mid_price'].shift(1)).fillna(0)\n",
    "df['realized_volatility'] = (\n",
    "    df['log_return']\n",
    "    .rolling(window=30, min_periods=1)\n",
    "    .apply(lambda x: np.sqrt(np.sum(x**2)))\n",
    ")\n",
    "\n",
    "df['rv_future'] = df['realized_volatility'].shift(-30)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "feature_cols = ['bid_price1', 'ask_price1', 'bid_price2', 'ask_price2',\n",
    "                'mid_price', 'spread', 'imbalance', 'wap', 'log_wap_return']\n",
    "\n",
    "target_col = 'rv_future'\n",
    "\n",
    "# Scaling\n",
    "x_scaler = MinMaxScaler()\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "X_all = x_scaler.fit_transform(df[feature_cols])\n",
    "y_all = y_scaler.fit_transform(df[[target_col]]).flatten()\n",
    "\n",
    "# Rolling sequences\n",
    "SEQ_LEN = 30\n",
    "\n",
    "def build_sequences(X, y, seq_len):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - seq_len):\n",
    "        X_seq.append(X[i:i+seq_len].flatten())\n",
    "        y_seq.append(y[i + seq_len])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_seq, y_seq = build_sequences(X_all, y_all, SEQ_LEN)\n",
    "\n",
    "split_idx = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:split_idx], X_seq[split_idx:]\n",
    "y_train, y_test = y_seq[:split_idx], y_seq[split_idx:]\n",
    "\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(64,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-4,\n",
    "    alpha=1e-4,\n",
    "    max_iter=500,\n",
    "    shuffle=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "pred_scaled = mlp.predict(X_test)\n",
    "actual_scaled = y_test\n",
    "\n",
    "# Inverse Transform\n",
    "predictions = y_scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()\n",
    "actuals = y_scaler.inverse_transform(actual_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Evaluation\n",
    "rmse = root_mean_squared_error(actuals, predictions)\n",
    "r2 = r2_score(actuals, predictions)\n",
    "\n",
    "def qlike_safe(actual, forecast, eps=1e-8):\n",
    "    a = np.clip(actual, eps, None)\n",
    "    f = np.clip(forecast, eps, None)\n",
    "    r = a / f\n",
    "    return np.mean(r - np.log(r) - 1.0)\n",
    "\n",
    "ql = qlike_safe(actuals, predictions)\n",
    "\n",
    "print(f\"Out-of-sample RMSE: {rmse:.6f}\")\n",
    "print(f\"R² score: {r2:.6f}\")\n",
    "print(f\"QLIKE: {ql:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(actuals, predictions, s=6, alpha=0.6, edgecolor=\"none\")\n",
    "max_val = max(np.max(actuals), np.max(predictions))\n",
    "plt.plot([0, max_val], [0, max_val], linestyle=\"--\")\n",
    "plt.title(\"Predicted vs. Realised Volatility\")\n",
    "plt.xlabel(\"True σ\")\n",
    "plt.ylabel(\"Predicted σ\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = predictions - actuals\n",
    "plt.figure()\n",
    "plt.hist(residuals, bins=60, alpha=0.8)\n",
    "plt.title(\"Residual Distribution (Prediction - Truth)\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(actuals, label='True')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.title('Predicted vs True Volatility over Time')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Volatility')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
