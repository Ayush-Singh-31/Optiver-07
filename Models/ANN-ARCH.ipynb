{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62bfe8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta as ta\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import t\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50354773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/ayush/Documents/University/Year 03/Sem 01/DATA3888/Optiver-07/Data/S27FE-10K.csv\")\n",
    "df['time_id'] = pd.to_datetime(df['time_id'], errors='coerce')\n",
    "df = df.set_index('time_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb0b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReturnCalculation(Database, lag=1):\n",
    "    # Use the already-computed log_return values.\n",
    "    DailyReturns = Database['log_return'].values\n",
    "    Index = Database.index\n",
    "    # Optionally, if we want to shift the series for a lag greater than 1\n",
    "    if lag > 1:\n",
    "        DailyReturns = np.append(np.repeat(np.nan, lag), DailyReturns[lag:])\n",
    "    return DailyReturns, Index\n",
    "\n",
    "def SDCalculation(DailyReturns, LagSD):\n",
    "    dimension = DailyReturns.shape[0]\n",
    "    dif = LagSD\n",
    "    Out = np.zeros(dimension - dif)\n",
    "    for i in range(dimension - dif):\n",
    "        Out[i] = np.std(DailyReturns[i:i+LagSD], ddof=1)\n",
    "    return np.append(np.repeat(np.nan, dif), Out)\n",
    "\n",
    "def TrueSDCalculation(DailyReturns, LagSD):\n",
    "    dimension = DailyReturns.shape[0]\n",
    "    dif = LagSD\n",
    "    Out = np.zeros(dimension - dif + 1)\n",
    "    for i in range(dimension - dif + 1):\n",
    "        Out[i] = np.std(DailyReturns[i:i+LagSD], ddof=1)\n",
    "    return np.append(Out, np.repeat(np.nan, dif-1))\n",
    "\n",
    "# Create a database that contains the returns and volatility measures.\n",
    "def DatabaseGeneration(Database, Lag=1, LagSD=5):\n",
    "    DailyReturns, Index = ReturnCalculation(Database, Lag)\n",
    "    DailyReturnsOld = np.append(np.repeat(np.nan, 1), DailyReturns[0:(DailyReturns.shape[0]-1)])\n",
    "    SD = SDCalculation(DailyReturns, LagSD)\n",
    "    TrueSD = TrueSDCalculation(DailyReturns, LagSD)\n",
    "    Data = pd.DataFrame({\n",
    "        'DailyReturns': DailyReturns,\n",
    "        'SD': SD,\n",
    "        'TrueSD': TrueSD,\n",
    "        'DailyReturnsOld': DailyReturnsOld\n",
    "    }, index=Index)\n",
    "    return Data.dropna()\n",
    "\n",
    "# Similar function for forecasting (without dropping NaNs).\n",
    "def DatabaseGenerationForecast(Database, Lag, LagSD):\n",
    "    DailyReturns, Index = ReturnCalculation(Database, Lag)\n",
    "    DailyReturnsOld = np.append(np.repeat(np.nan, 1), DailyReturns[0:(DailyReturns.shape[0]-1)])\n",
    "    SD = SDCalculation(DailyReturns, LagSD)\n",
    "    TrueSD = TrueSDCalculation(DailyReturns, LagSD)\n",
    "    Data = pd.DataFrame({\n",
    "        'DailyReturns': DailyReturns,\n",
    "        'SD': SD,\n",
    "        'TrueSD': TrueSD,\n",
    "        'DailyReturnsOld': DailyReturnsOld\n",
    "    }, index=Index)\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85653b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARCH-Family Model Functions\n",
    "\n",
    "def GARCH_Model_Student(Data):\n",
    "    AR_Data = Data['DailyReturns'] * 100\n",
    "    GARCH11 = arch_model(AR_Data, dist='t')\n",
    "    res_GARCH11 = GARCH11.fit(disp='off')\n",
    "    CV_GARCH11 = res_GARCH11.conditional_volatility\n",
    "    For_CV_GARCH11 = np.array(res_GARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
    "    return GARCH11, res_GARCH11, CV_GARCH11, For_CV_GARCH11\n",
    "\n",
    "def GJR_GARCH_Model_Student(Data):\n",
    "    AR_Data = Data['DailyReturns'] * 100\n",
    "    GJR_GARCH11 = arch_model(AR_Data, p=1, o=1, q=1, dist='t')\n",
    "    res_GJR_GARCH11 = GJR_GARCH11.fit(disp='off')\n",
    "    CV_GJR_GARCH11 = res_GJR_GARCH11.conditional_volatility\n",
    "    For_CV_GJR_GARCH11 = np.array(res_GJR_GARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
    "    return GJR_GARCH11, res_GJR_GARCH11, CV_GJR_GARCH11, For_CV_GJR_GARCH11\n",
    "\n",
    "def TARCH_Model_Student(Data):\n",
    "    AR_Data = Data['DailyReturns'] * 100\n",
    "    TARCH11 = arch_model(AR_Data, p=1, o=1, q=1, power=1.0, dist='t')\n",
    "    res_TARCH11 = TARCH11.fit(disp='off')\n",
    "    CV_TARCH11 = res_TARCH11.conditional_volatility\n",
    "    For_CV_TARCH11 = np.array(res_TARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
    "    return TARCH11, res_TARCH11, CV_TARCH11, For_CV_TARCH11\n",
    "\n",
    "def EGARCH_Model_Student(Data):\n",
    "    AR_Data = Data['DailyReturns'] * 100\n",
    "    EGARCH11 = arch_model(AR_Data, dist='t', vol=\"EGARCH\")\n",
    "    res_EGARCH11 = EGARCH11.fit(disp='off')\n",
    "    CV_EGARCH11 = res_EGARCH11.conditional_volatility\n",
    "    For_CV_EGARCH11 = np.array(res_EGARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
    "    return EGARCH11, res_EGARCH11, CV_EGARCH11, For_CV_EGARCH11\n",
    "\n",
    "def AVGARCH_Model_Student(Data):\n",
    "    AR_Data = Data['DailyReturns'] * 100\n",
    "    AVGARCH11 = arch_model(AR_Data, dist='t', power=1)\n",
    "    res_AVGARCH11 = AVGARCH11.fit(disp='off', options={'maxiter': 1000})\n",
    "    CV_AVGARCH11 = res_AVGARCH11.conditional_volatility\n",
    "    For_CV_AVGARCH11 = np.array(res_AVGARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
    "    return AVGARCH11, res_AVGARCH11, CV_AVGARCH11, For_CV_AVGARCH11\n",
    "\n",
    "def FIGARCH_Model_Student(Data):\n",
    "    AR_Data = Data['DailyReturns'] * 100\n",
    "    FIGARCH11 = arch_model(AR_Data, dist='t', vol=\"FIGARCH\")\n",
    "    res_FIGARCH11 = FIGARCH11.fit(disp='off')\n",
    "    CV_FIGARCH11 = res_FIGARCH11.conditional_volatility\n",
    "    For_CV_FIGARCH11 = np.array(res_FIGARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
    "    return FIGARCH11, res_FIGARCH11, CV_FIGARCH11, For_CV_FIGARCH11\n",
    "\n",
    "def AR_Models(Data):\n",
    "    GARCH, GARCH_Parameters, CV_GARCH, For_CV_GARCH = GARCH_Model_Student(Data)\n",
    "    GJR_GARCH, GJR_GARCH_Parameters, CV_GJR_GARCH, For_CV_GJR_GARCH = GJR_GARCH_Model_Student(Data)\n",
    "    TARCH, TARCH_Parameters, CV_TARCH, For_CV_TARCH = TARCH_Model_Student(Data)\n",
    "    EGARCH, EGARCH_Parameters, CV_EGARCH, For_CV_EGARCH = EGARCH_Model_Student(Data)\n",
    "    AVGARCH, AVGARCH_Parameters, CV_AVGARCH, For_CV_AVGARCH = AVGARCH_Model_Student(Data)\n",
    "    FIGARCH, FIGARCH_Parameters, CV_FIGARCH, For_CV_FIGARCH = FIGARCH_Model_Student(Data)\n",
    "    return (GARCH_Parameters, CV_GARCH, For_CV_GARCH, \n",
    "            GJR_GARCH_Parameters, CV_GJR_GARCH, For_CV_GJR_GARCH,\n",
    "            TARCH_Parameters, CV_TARCH, For_CV_TARCH,\n",
    "            EGARCH_Parameters, CV_EGARCH, For_CV_EGARCH,\n",
    "            AVGARCH_Parameters, CV_AVGARCH, For_CV_AVGARCH,\n",
    "            FIGARCH_Parameters, CV_FIGARCH, For_CV_FIGARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28651347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model and Data Preparation for Deep Learning\n",
    "\n",
    "def LSTM_Model(Shape1, Shape2, Dropout, LearningRate):\n",
    "    Inputs = tf.keras.Input(shape=(Shape1, Shape2), name=\"Input\")\n",
    "    X = tf.keras.layers.LSTM(units=32, dropout=Dropout, return_sequences=False)(Inputs)\n",
    "    X = tf.keras.layers.Dense(8, activation=tf.nn.sigmoid)(X)\n",
    "    X = tf.keras.layers.Dropout(Dropout)(X)\n",
    "    Output = tf.keras.layers.Dense(1, activation=None, name=\"Output\")(X)\n",
    "    model = tf.keras.Model(inputs=Inputs, outputs=Output)\n",
    "    Opt = tf.keras.optimizers.Adam(learning_rate=LearningRate)\n",
    "    model.compile(optimizer=Opt, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "def LSTM_Database(Timestep, XData_AR, YData_AR):\n",
    "    Features = XData_AR.shape[1]\n",
    "    Sample = XData_AR.shape[0] - Timestep + 1\n",
    "    XDataTrainScaledRNN = np.zeros([Sample, Timestep, Features])\n",
    "    YDataTrainRNN = np.zeros(Sample)\n",
    "    for i in range(Sample):\n",
    "        XDataTrainScaledRNN[i, :, :] = XData_AR[i:(Timestep + i)]\n",
    "        YDataTrainRNN[i] = YData_AR[Timestep + i - 1]\n",
    "    return XDataTrainScaledRNN, YDataTrainRNN\n",
    "\n",
    "# Build forecast database including ARCH model outputs.\n",
    "def DatabaseGenerationForecast_AR(Database, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH):\n",
    "    Data_Forecast = DatabaseGenerationForecast(Database, Lag, LagSD).iloc[(-LagSD + 1)]\n",
    "    Index_Forecast = DatabaseGenerationForecast(Database, Lag, LagSD).index[(-LagSD + 1)]\n",
    "    XDataForecast = {\n",
    "        'SD': Data_Forecast['SD'],\n",
    "        'DailyReturnsOld': Data_Forecast['DailyReturnsOld'],\n",
    "        'CV_GARCH': For_CV_GARCH / 100,\n",
    "        'CV_GJR_GARCH': For_CV_GJR_GARCH / 100,\n",
    "        'CV_TARCH': For_CV_TARCH / 100,\n",
    "        'CV_EGARCH': For_CV_EGARCH / 100,\n",
    "        'CV_AVGARCH': For_CV_AVGARCH / 100,\n",
    "        'CV_FIGARCH': For_CV_FIGARCH / 100\n",
    "    }\n",
    "    return pd.DataFrame([XDataForecast], index=[Index_Forecast]), Data_Forecast['DailyReturns']\n",
    "\n",
    "# LSTM-ARCH forecast function: scales, reshapes data and makes prediction.\n",
    "def LSTM_ARCH_Forecast(Database, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH,\n",
    "                       For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH, Scaled_Norm, XData_AR, model, Timestep):\n",
    "    XDataForecast, ReturnForecast = DatabaseGenerationForecast_AR(\n",
    "        Database, Lag, LagSD,\n",
    "        For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH,\n",
    "        For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH\n",
    "    )\n",
    "    XDataForecast = pd.concat([XData_AR, XDataForecast])\n",
    "    XDataForecastTotalScaled = Scaled_Norm.transform(XDataForecast)\n",
    "    XDataForecastTotalScaled_T, Y_T = LSTM_Database(Timestep, XDataForecastTotalScaled, \n",
    "                                                    np.zeros(XDataForecastTotalScaled.shape[0]))\n",
    "    TransformerPrediction = model.predict(XDataForecastTotalScaled_T)\n",
    "    return (TransformerPrediction[-1][0],\n",
    "            XDataForecast.index[-1],\n",
    "            TransformerPrediction[0:(XDataForecastTotalScaled_T.shape[0] - 1)],\n",
    "            ReturnForecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e3e4372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaR Calculation Functions\n",
    "\n",
    "def LSTM_ARCH_VaR(Alpha, HistoricalReturns, ForecastedSigma, DF):\n",
    "    HistoricalMean = np.mean(HistoricalReturns)\n",
    "    ScaleParameter = np.sqrt((ForecastedSigma**2) * ((DF - 2) / DF))\n",
    "    VaR = -t.ppf(Alpha, DF, loc=HistoricalMean, scale=ScaleParameter)\n",
    "    return VaR\n",
    "\n",
    "def VaR_AR_Model(AR_Model, AR_Model_Results, Alpha):\n",
    "    Cond_Var = AR_Model_Results.forecast(horizon=1).variance.dropna()\n",
    "    Cond_Mean = AR_Model_Results.forecast(horizon=1).mean.dropna()\n",
    "    Quantile_Dist = AR_Model.distribution.ppf([Alpha], AR_Model_Results.params[-1:])\n",
    "    VaR = (-Cond_Mean - np.sqrt(Cond_Var) * Quantile_Dist) / 100\n",
    "    return VaR.values\n",
    "\n",
    "def VaR_AR_Total(Alpha, GARCH_fit, GJR_GARCH_fit, TARCH_fit, EGARCH_fit, AVGARCH_fit, FIGARCH_fit, \n",
    "                 GARCH, GJR_GARCH, TARCH, EGARCH, AVGARCH, FIGARCH):\n",
    "    VaR_GARCH = VaR_AR_Model(GARCH, GARCH_fit, Alpha)\n",
    "    VaR_GJR_GARCH = VaR_AR_Model(GJR_GARCH, GJR_GARCH_fit, Alpha)\n",
    "    VaR_TARCH = VaR_AR_Model(TARCH, TARCH_fit, Alpha)\n",
    "    VaR_EGARCH = VaR_AR_Model(EGARCH, EGARCH_fit, Alpha)\n",
    "    VaR_AVGARCH = VaR_AR_Model(AVGARCH, AVGARCH_fit, Alpha)\n",
    "    VaR_FIGARCH = VaR_AR_Model(FIGARCH, FIGARCH_fit, Alpha)\n",
    "    return {\n",
    "        'VaR_GARCH': VaR_GARCH,\n",
    "        'VaR_GJR_GARCH': VaR_GJR_GARCH,\n",
    "        'VaR_TARCH': VaR_TARCH,\n",
    "        'VaR_EGARCH': VaR_EGARCH,\n",
    "        'VaR_AVGARCH': VaR_AVGARCH,\n",
    "        'VaR_FIGARCH': VaR_FIGARCH\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d759015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final LSTM-ARCH Fitting Function\n",
    "\n",
    "def LSTM_ARCH_Fit(Data, Lag=1, LagSD=5, Timestep=10, Dropout=0.05, LearningRate=0.001,\n",
    "                  Epochs=10000, Alpha=0.005, DF=4, BatchSize=64):\n",
    "    # Generate ARCH input database using the modified returns\n",
    "    Data_AR = DatabaseGeneration(Data, Lag, LagSD)\n",
    "    \n",
    "    # Fit ARCH models on the preprocessed data\n",
    "    GARCH, GARCH_Parameters, CV_GARCH, For_CV_GARCH = GARCH_Model_Student(Data_AR)\n",
    "    GJR_GARCH, GJR_GARCH_Parameters, CV_GJR_GARCH, For_CV_GJR_GARCH = GJR_GARCH_Model_Student(Data_AR)\n",
    "    TARCH, TARCH_Parameters, CV_TARCH, For_CV_TARCH = TARCH_Model_Student(Data_AR)\n",
    "    EGARCH, EGARCH_Parameters, CV_EGARCH, For_CV_EGARCH = EGARCH_Model_Student(Data_AR)\n",
    "    AVGARCH, AVGARCH_Parameters, CV_AVGARCH, For_CV_AVGARCH = AVGARCH_Model_Student(Data_AR)\n",
    "    FIGARCH, FIGARCH_Parameters, CV_FIGARCH, For_CV_FIGARCH = FIGARCH_Model_Student(Data_AR)\n",
    "    \n",
    "    # Append conditional volatilities from ARCH models to the database\n",
    "    Data_AR = pd.concat([\n",
    "        Data_AR,\n",
    "        CV_GARCH.rename('CV_GARCH') / 100,\n",
    "        CV_GJR_GARCH.rename('CV_GJR_GARCH') / 100,\n",
    "        CV_TARCH.rename('CV_TARCH') / 100,\n",
    "        CV_EGARCH.rename('CV_EGARCH') / 100,\n",
    "        CV_AVGARCH.rename('CV_AVGARCH') / 100,\n",
    "        CV_FIGARCH.rename('CV_FIGARCH') / 100\n",
    "    ], axis=1)\n",
    "    \n",
    "    if Data_AR.shape[0] != DatabaseGeneration(Data, Lag, LagSD).shape[0]:\n",
    "        print(\"Error in DB Generation\")\n",
    "    \n",
    "    # Prepare explanatory (X) and response (Y) variables.\n",
    "    # In this setting, we drop 'DailyReturns' and 'TrueSD' from features and use 'TrueSD' as Y.\n",
    "    XData_AR = Data_AR.drop(Data_AR.columns[[0, 2]], axis=1)\n",
    "    YData_AR = Data_AR['TrueSD']\n",
    "    \n",
    "    # Normalize explanatory variables.\n",
    "    Scaled_Norm = preprocessing.StandardScaler().fit(XData_AR)\n",
    "    XData_AR_Norm = Scaled_Norm.transform(XData_AR)\n",
    "    \n",
    "    # Rearrange data for LSTM input.\n",
    "    XData_AR_Norm_T, YData_AR_Norm_T = LSTM_Database(Timestep, XData_AR_Norm, YData_AR)\n",
    "    \n",
    "    # Define and train the LSTM model.\n",
    "    model = LSTM_Model(XData_AR_Norm_T.shape[1], XData_AR_Norm_T.shape[2], Dropout, LearningRate)\n",
    "    model.fit(XData_AR_Norm_T, YData_AR_Norm_T, epochs=Epochs, verbose=0, batch_size=BatchSize)\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Forecast the next volatility value using the hybrid model.\n",
    "    Forecast, Date_Forecast, TrainPrediction, ReturnForecast = LSTM_ARCH_Forecast(\n",
    "        Data, Lag, LagSD,\n",
    "        For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH,\n",
    "        For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH,\n",
    "        Scaled_Norm, XData_AR, model, Timestep\n",
    "    )\n",
    "    \n",
    "    # Compute Value-at-Risk (VaR) using the forecasted volatility.\n",
    "    VaR = LSTM_ARCH_VaR(Alpha, Data['log_return'].values, Forecast, DF)\n",
    "    return {\n",
    "        'LSTM_ARCH_model': model,\n",
    "        'Forecast_LSTM_ARCH': Forecast,\n",
    "        'Date_Forecast': Date_Forecast,\n",
    "        'TrainPrediction': TrainPrediction,\n",
    "        'Scaler': Scaled_Norm,\n",
    "        'Forecast_GARCH': For_CV_GARCH,\n",
    "        'Forecast_GJR_GARCH': For_CV_GJR_GARCH,\n",
    "        'Forecast_TARCH': For_CV_TARCH,\n",
    "        'Forecast_EGARCH': For_CV_EGARCH,\n",
    "        'Forecast_AVGARCH': For_CV_AVGARCH,\n",
    "        'Forecast_FIGARCH': For_CV_FIGARCH,\n",
    "        'ReturnForecast': ReturnForecast,\n",
    "        'GARCH_fit': GARCH_Parameters,\n",
    "        'GJR_GARCH_fit': GJR_GARCH_Parameters,\n",
    "        'TARCH_fit': TARCH_Parameters,\n",
    "        'EGARCH_fit': EGARCH_Parameters,\n",
    "        'AVGARCH_fit': AVGARCH_Parameters,\n",
    "        'FIGARCH_fit': FIGARCH_Parameters,\n",
    "        'GARCH': GARCH,\n",
    "        'GJR_GARCH': GJR_GARCH,\n",
    "        'TARCH': TARCH,\n",
    "        'EGARCH': EGARCH,\n",
    "        'AVGARCH': AVGARCH,\n",
    "        'FIGARCH': FIGARCH,\n",
    "        'YData_Train': YData_AR_Norm_T,\n",
    "        'VaR': VaR\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc8e6d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayush/Documents/University/Year 03/Sem 01/DATA3888/Optiver-07/volt/lib/python3.12/site-packages/arch/univariate/base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.00263. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ayush/Documents/University/Year 03/Sem 01/DATA3888/Optiver-07/volt/lib/python3.12/site-packages/arch/univariate/base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.00263. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ayush/Documents/University/Year 03/Sem 01/DATA3888/Optiver-07/volt/lib/python3.12/site-packages/arch/univariate/base.py:768: ConvergenceWarning: The optimizer returned code 4. The message is:\n",
      "Inequality constraints incompatible\n",
      "See scipy.optimize.fmin_slsqp for code meaning.\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ayush/Documents/University/Year 03/Sem 01/DATA3888/Optiver-07/volt/lib/python3.12/site-packages/arch/univariate/base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.00263. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ayush/Documents/University/Year 03/Sem 01/DATA3888/Optiver-07/volt/lib/python3.12/site-packages/arch/univariate/base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.00263. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ayush/Documents/University/Year 03/Sem 01/DATA3888/Optiver-07/volt/lib/python3.12/site-packages/arch/univariate/base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.00263. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ayush/Documents/University/Year 03/Sem 01/DATA3888/Optiver-07/volt/lib/python3.12/site-packages/arch/univariate/base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.00263. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n",
      "/var/folders/0s/bt69j7tj0pd5rl5dzr4n6bth0000gn/T/ipykernel_2028/3603268024.py:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  YDataTrainRNN[i] = YData_AR[Timestep + i - 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step\n",
      "Forecasted Volatility: -0.06175645\n",
      "Forecast Date: 1970-01-01 00:00:00.000000373\n",
      "Calculated VaR: 0.20105435538316754\n"
     ]
    }
   ],
   "source": [
    "random.seed(38888)\n",
    "result = LSTM_ARCH_Fit(df, Lag=1, LagSD=5, Timestep=20, Dropout=0.05,\n",
    "                        LearningRate=0.001, Epochs=100, Alpha=0.005, DF=4, BatchSize=64)\n",
    "\n",
    "print(\"Forecasted Volatility:\", result['Forecast_LSTM_ARCH'])\n",
    "print(\"Forecast Date:\", result['Date_Forecast'])\n",
    "print(\"Calculated VaR:\", result['VaR'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
